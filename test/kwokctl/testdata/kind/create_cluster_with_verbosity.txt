# Save cluster config to <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/kwok.yaml
mkdir -p <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>
cat <<EOF ><ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/apiserver-tracing-config.yaml
apiVersion: apiserver.config.k8s.io/v1alpha1
kind: TracingConfiguration
endpoint: 0.0.0.0:4317
samplingRatePerMillion: 1000000
EOF
cat <<EOF ><ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/kind.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 8000
    hostPort: 8000
    protocol: TCP
  - containerPort: 9090
    hostPort: 9090
    protocol: TCP
  - containerPort: 16686
    hostPort: 16686
    protocol: TCP
  kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    etcd:
      local:
        extraArgs:
          "log-level": "debug"
  - |
    kind: ClusterConfiguration
    apiServer:
      extraArgs:
        "tracing-config-file": "/etc/kubernetes/apiserver-tracing-config.yaml"
        "v": "4"
        "max-requests-inflight": "0"
        "max-mutating-requests-inflight": "0"
        "enable-priority-and-fairness": "false"
      extraVolumes:
      - name: apiserver-tracing-config
        hostPath: /var/components/apiserver/etc/kubernetes/apiserver-tracing-config.yaml
        mountPath: /etc/kubernetes/apiserver-tracing-config.yaml
        readOnly: true
        pathType: File
  - |
    kind: ClusterConfiguration
    controllerManager:
      extraArgs:
        "v": "4"
        "kube-api-qps": "5000"
        "kube-api-burst": "10000"
  - |
    kind: ClusterConfiguration
    scheduler:
      extraArgs:
        "v": "4"
        "kube-api-qps": "5000"
        "kube-api-burst": "10000"
  # mount the local file on the control plane
  extraMounts:
  - hostPath: <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/kwok.yaml
    containerPath: /etc/kwok/kwok.yaml
    readOnly: true
  - hostPath: <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/apiserver-tracing-config.yaml
    containerPath: /var/components/apiserver/etc/kubernetes/apiserver-tracing-config.yaml
    readOnly: true
EOF
cat <<EOF ><ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/kwok-controller-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    app: kwok-controller
  name: kwok-controller
  namespace: kube-system
spec:
  containers:
  - args:
    - --config=/etc/kwok/kwok.yaml
    - --v=DEBUG
    - --manage-all-nodes=false
    - --manage-nodes-with-annotation-selector=kwok.x-k8s.io/node=fake
    - --manage-nodes-with-label-selector=
    - --disregard-status-with-annotation-selector=kwok.x-k8s.io/status=custom
    - --disregard-status-with-label-selector=
    - --kubeconfig=/etc/kubernetes/admin.conf
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    - --node-ip=$(POD_IP)
    - --node-name=kwok-controller.kube-system.svc
    - --node-port=10247
    - --node-lease-duration-seconds=40
    env:
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    image: 'localhost/kwok:test'
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: /healthz
        port: 10247
        scheme: HTTP
      initialDelaySeconds: 2
      periodSeconds: 10
      timeoutSeconds: 2
    name: kwok-controller
    readinessProbe:
      failureThreshold: 5
      httpGet:
        path: /healthz
        port: 10247
        scheme: HTTP
      initialDelaySeconds: 2
      periodSeconds: 20
      timeoutSeconds: 2
    volumeMounts:
    - mountPath: /etc/kubernetes/admin.conf
      name: kubeconfig
      readOnly: true
    - mountPath: /etc/kwok/kwok.yaml
      name: config
      readOnly: true
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
  hostNetwork: true
  restartPolicy: Always
  volumes:
  - hostPath:
      path: /etc/kubernetes/admin.conf
      type: FileOrCreate
    name: kubeconfig
  - hostPath:
      path: /etc/kwok/kwok.yaml
      type: FileOrCreate
    name: config
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
EOF
cat <<EOF ><ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/dashboard-deployment.yaml
apiVersion: v1
kind: Pod
metadata:
  name: dashboard
  namespace: kube-system
  labels:
    app: dashboard
spec:
  containers:
  - name: dashboard
    image: docker.io/kubernetesui/dashboard:v2.7.0
    args:
    - --kubeconfig=/etc/kubernetes/admin.conf
    - --insecure-bind-address=0.0.0.0
    - --insecure-port=8000
    - --bind-address=127.0.0.1
    - --port=0
    - --enable-insecure-login
    - --enable-skip-login
    - --disable-settings-authorizer
    - --metrics-provider=none
    - --namespace=kube-system
    - --system-banner=Welcome to kwok-<CLUSTER_NAME>
    volumeMounts:
    - mountPath: /etc/kubernetes/admin.conf
      name: kubeconfig
      readOnly: true
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    securityContext:
      privileged: true
      runAsUser: 0
      runAsGroup: 0
  restartPolicy: Always
  hostNetwork: true
  nodeName: kwok-<CLUSTER_NAME>-control-plane
  volumes:
  - hostPath:
      path: /etc/kubernetes/admin.conf
      type: FileOrCreate
    name: kubeconfig
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
EOF
cat <<EOF ><ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/metrics-server-deployment.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    k8s-app: metrics-server
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
    rbac.authorization.k8s.io/aggregate-to-view: "true"
  name: system:aggregated-metrics-reader
rules:
- apiGroups:
  - metrics.k8s.io
  resources:
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    k8s-app: metrics-server
  name: system:metrics-server
rules:
- apiGroups:
  - ""
  resources:
  - nodes/metrics
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server-auth-reader
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: extension-apiserver-authentication-reader
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server:system:auth-delegator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    k8s-app: metrics-server
  name: system:metrics-server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:metrics-server
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: v1
kind: Service
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server
  namespace: kube-system
spec:
  ports:
  - name: https
    port: 443
    protocol: TCP
    targetPort: https
  selector:
    k8s-app: metrics-server
---
apiVersion: v1
kind: Pod
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server
  namespace: kube-system
spec:
  containers:
  - args:
    - --cert-dir=/tmp
    - --secure-port=4443
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --kubelet-use-node-status-port
    - --metric-resolution=15s
    - --kubelet-insecure-tls
    - --v=4
    image: registry.k8s.io/metrics-server/metrics-server:v0.6.3
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: /livez
        port: https
        scheme: HTTPS
      periodSeconds: 10
    name: metrics-server
    ports:
    - containerPort: 4443
      name: https
      protocol: TCP
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: /readyz
        port: https
        scheme: HTTPS
      initialDelaySeconds: 20
      periodSeconds: 10
    volumeMounts:
    - mountPath: /tmp
      name: tmp-dir
  hostNetwork: true
  restartPolicy: Always
  serviceAccountName: metrics-server
  nodeName: kwok-<CLUSTER_NAME>-control-plane
  volumes:
  - emptyDir: {}
    name: tmp-dir
---
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  labels:
    k8s-app: metrics-server
  name: v1beta1.metrics.k8s.io
spec:
  group: metrics.k8s.io
  groupPriorityMinimum: 100
  insecureSkipTLSVerify: true
  service:
    name: metrics-server
    namespace: kube-system
  version: v1beta1
  versionPriority: 100
EOF
cat <<EOF ><ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/prometheus-deployment.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-configmap
  namespace: kube-system
data:
  prometheus.yaml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
    alerting:
      alertmanagers:
      - follow_redirects: true
        enable_http2: true
        scheme: http
        timeout: 10s
        api_version: v2
        static_configs:
        - targets: [ ]
    scrape_configs:
    - job_name: "kwok-service-discovery"
      http_sd_configs:
      - url: http://localhost:10247/discovery/prometheus
    - job_name: "prometheus"
      scheme: http
      honor_timestamps: true
      metrics_path: /metrics
      follow_redirects: true
      enable_http2: true
      static_configs:
      - targets:
        - "localhost:9090"
    - job_name: "etcd"
      scheme: https
      honor_timestamps: true
      metrics_path: /metrics
      follow_redirects: true
      enable_http2: true
      tls_config:
        cert_file: /etc/kubernetes/pki/apiserver-etcd-client.crt
        key_file: /etc/kubernetes/pki/apiserver-etcd-client.key
        insecure_skip_verify: true
      static_configs:
      - targets:
        - "localhost:2379"
    - job_name: "kwok-controller"
      scheme: http
      honor_timestamps: true
      metrics_path: /metrics
      follow_redirects: true
      enable_http2: true
      static_configs:
      - targets:
        - "localhost:10247"
    - job_name: "kube-apiserver"
      scheme: https
      honor_timestamps: true
      metrics_path: /metrics
      follow_redirects: true
      enable_http2: true
      tls_config:
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      static_configs:
      - targets:
        - "localhost:6443"
    - job_name: "kube-controller-manager"
      scheme: https
      honor_timestamps: true
      metrics_path: /metrics
      follow_redirects: true
      enable_http2: true
      tls_config:
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      static_configs:
      - targets:
        - "localhost:10257"
    - job_name: "kube-scheduler"
      scheme: https
      honor_timestamps: true
      metrics_path: /metrics
      follow_redirects: true
      enable_http2: true
      tls_config:
        insecure_skip_verify: true
      bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      static_configs:
      - targets:
        - "localhost:10259"
---
apiVersion: v1
kind: Pod
metadata:
  name: prometheus
  namespace: kube-system
spec:
  containers:
  - name: prometheus
    image: docker.io/prom/prometheus:v2.44.0
    args:
    - --config.file=/etc/prometheus/prometheus.yaml
    - --log.level=debug
    securityContext:
      runAsUser: 0
    volumeMounts:
    - name: config-volume
      mountPath: /etc/prometheus/
      readOnly: true
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
  volumes:
  - name: config-volume
    configMap:
      name: prometheus-configmap
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  serviceAccount: prometheus
  serviceAccountName: prometheus
  restartPolicy: Always
  hostNetwork: true
  nodeName: kwok-<CLUSTER_NAME>-control-plane
EOF
cat <<EOF ><ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/jaeger-deployment.yaml
apiVersion: v1
kind: Pod
metadata:
  name: jaeger
  namespace: kube-system
  labels:
    app: jaeger
spec:
  containers:
  - name: jaeger
    image: docker.io/jaegertracing/all-in-one:1.45.0
    args:
    - --collector.otlp.enabled=true
    - --log-level=debug
  restartPolicy: Always
  hostNetwork: true
  nodeName: kwok-<CLUSTER_NAME>-control-plane
EOF
docker pull docker.io/kindest/node:v1.28.0
docker pull localhost/kwok:test
docker pull docker.io/kubernetesui/dashboard:v2.7.0
docker pull registry.k8s.io/metrics-server/metrics-server:v0.6.3
docker pull docker.io/prom/prometheus:v2.44.0
docker pull docker.io/jaegertracing/all-in-one:1.45.0
# Save cluster config to <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/kwok.yaml
KIND_EXPERIMENTAL_PROVIDER=docker kind create cluster --config <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/kind.yaml --name kwok-<CLUSTER_NAME> --image docker.io/kindest/node:v1.28.0 --wait 29m
KIND_EXPERIMENTAL_PROVIDER=docker kind load docker-image localhost/kwok:test --name kwok-<CLUSTER_NAME>
KIND_EXPERIMENTAL_PROVIDER=docker kind load docker-image docker.io/kubernetesui/dashboard:v2.7.0 --name kwok-<CLUSTER_NAME>
KIND_EXPERIMENTAL_PROVIDER=docker kind load docker-image registry.k8s.io/metrics-server/metrics-server:v0.6.3 --name kwok-<CLUSTER_NAME>
KIND_EXPERIMENTAL_PROVIDER=docker kind load docker-image docker.io/prom/prometheus:v2.44.0 --name kwok-<CLUSTER_NAME>
KIND_EXPERIMENTAL_PROVIDER=docker kind load docker-image docker.io/jaegertracing/all-in-one:1.45.0 --name kwok-<CLUSTER_NAME>
kubectl config view --minify=true --raw=true
cat <<EOF ><ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/kubeconfig.yaml
EOF
docker cp <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/kwok-controller-pod.yaml kwok-<CLUSTER_NAME>-control-plane:/etc/kubernetes/manifests/kwok-controller.yaml
mkdir -p <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/pki
docker cp kwok-<CLUSTER_NAME>-control-plane:/etc/kubernetes/pki/ca.crt <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/pki/ca.crt
docker cp kwok-<CLUSTER_NAME>-control-plane:/etc/kubernetes/pki/ca.key <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/pki/ca.key
kubectl apply -f <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/dashboard-deployment.yaml
kubectl apply -f <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/metrics-server-deployment.yaml
kubectl apply -f <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/prometheus-deployment.yaml
kubectl apply -f <ROOT_DIR>/workdir/clusters/<CLUSTER_NAME>/jaeger-deployment.yaml
kubectl cordon kwok-<CLUSTER_NAME>-control-plane
# Add context kwok-<CLUSTER_NAME> to ~/.kube/config
